# -*- coding: utf-8 -*-
"""youtube_sumraizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yvpjpAS3hcWHbot8JVnGQLtj62g7Pk2z
"""

import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi
from transformers import pipeline
import nltk

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# Initialize the summarization model
summarizer = pipeline("summarization")

# Function to extract video ID from URL
def extract_video_id(url):
    if "youtube.com/watch?v=" in url:
        return url.split("youtube.com/watch?v=")[1].split("&")[0]
    elif "youtu.be/" in url:
        return url.split("youtu.be/")[1].split("&")[0]
    return url  # Return as is if already an ID

# Function to fetch and summarize YouTube video transcript
def summarize_youtube_video(video_id, max_word_count=10000):
    transcript = YouTubeTranscriptApi.get_transcript(video_id)
    text = " ".join([entry['text'] for entry in transcript])

    # Split text into smaller chunks (model limitation ~1024 tokens per request)
    chunk_size = 1000  # Adjust as needed
    text_chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]

    summaries = []
    for chunk in text_chunks:
        summary = summarizer(chunk, max_length=500, min_length=100, do_sample=False)[0]['summary_text']
        summaries.append(summary)

    # Combine all summaries into a single text
    final_summary = " ".join(summaries)

    # Trim to max_word_count if needed
    final_summary_words = final_summary.split()
    if len(final_summary_words) > max_word_count:
        final_summary = " ".join(final_summary_words[:max_word_count])

    return final_summary

# Streamlit GUI
st.title("YouTube Video Summarizer")
st.write("Enter a YouTube video URL or ID to generate a summary.")

video_url = st.text_input("Enter YouTube Video URL or ID:")

if st.button("Summarize Video") and video_url:
    video_id = extract_video_id(video_url)
    with st.spinner("Fetching and summarizing transcript..."):
        try:
            summary = summarize_youtube_video(video_id)
            st.subheader("Summary:")
            st.write(summary)
        except Exception as e:
            st.error(f"Error: {e}")

"""# Task
make this code working and error free

Here is all the data you need:
"you.txt"

## Data loading

### Subtask:
Load the content of "you.txt" into a string variable.

**Reasoning**:
Read the content of "you.txt" into a string variable named `code_string`.
"""

with open('you.txt', 'r') as f:
  code_string = f.read()

"""## Data exploration

### Subtask:
Analyze the content of the `code_string` variable to identify potential issues.

**Reasoning**:
Print the content of `code_string` to analyze it for potential issues like syntax errors, missing libraries, logical errors, and other potential issues.
"""

print(code_string)

"""**Reasoning**:
Analyze the `code_string` to identify potential issues as per the instructions, focusing on syntax errors, missing libraries, logical errors, and other potential problems.


"""

# Check for syntax errors (e.g., missing parentheses, incorrect indentation, invalid variable names).
try:
    compile(code_string, '<string>', 'exec')
except SyntaxError as e:
    print(f"Syntax Error: {e}")

# Check for missing libraries.
libraries = ['streamlit', 'youtube_transcript_api', 'transformers', 'nltk']
missing_libraries = []
for library in libraries:
    try:
        __import__(library)
    except ImportError:
        missing_libraries.append(library)

if missing_libraries:
    print(f"Missing Libraries: {missing_libraries}")

# Check for logical errors.
# 1. Check if the code is trying to access an undefined variable.
# 2. Check if the code is performing an operation on incompatible data types.

# Check for other potential issues.
# 1. Check if the code is using functions or variables that are not available in the current environment.
# 2. Check if the code is trying to access files or resources that do not exist.

"""## Data preparation

### Subtask:
Install the missing libraries and prepare the code for execution.

**Reasoning**:
Install the missing libraries `streamlit` and `youtube_transcript_api` using `pip install` and add the necessary import statements to the `code_string` variable.
"""

!pip install streamlit youtube_transcript_api

# Add import statements to the code_string variable
code_string = """
import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi

# Rest of the original code
""" + code_string

"""## Model training

### Subtask:
Execute the prepared code from `code_string`.

**Reasoning**:
Execute the prepared code using the `exec()` function.
"""

try:
  exec(code_string)
except Exception as e:
  print(f"Error during code execution: {e}")

"""## Model evaluation

### Subtask:
Evaluate the output of the code execution for any errors or unexpected behavior.

**Reasoning**:
Examine the output from the previous code execution to identify any errors or unexpected behavior.
"""

# Check for errors in the output from the previous code execution.
# Check if the summary is coherent and accurate.
# Check for any unexpected behavior like exceptions or warnings.

# Example checks (adjust based on the actual output):
# if "Error during code execution" in output:
#     print("Error detected during execution. Please check the logs for details.")
# if "Warning" in output:
#     print("Warnings were encountered during execution. Please check the logs for details.")

# You can add more checks based on the specific code and expected behavior.

"""**Reasoning**:
The previous code block didn't actually check for errors or unexpected behavior. I'll examine the previous output and write a code block that checks for errors and warnings specifically.


"""

# Check for errors in the output from the previous code execution.
if "Error during code execution:" in globals().get('output', ''):
    print("Error detected during execution. Please check the logs for details.")
    print(f"Error message: {globals().get('output', '').split('Error during code execution:')[1]}")

# Check for warnings in the output from the previous code execution.
if "WARNING" in globals().get('output', ''):
    print("Warnings were encountered during execution. Please check the logs for details.")

# Check for specific unexpected behavior based on the code.
# For example, if the code is supposed to print a summary,
# you can check if the summary is present in the output.

if "No transcript found" in globals().get('output', ''):
    print("No transcript found for the YouTube video.")

if not globals().get('output', ''):
  print("No output was generated.")

"""## Summary:

## Data Analysis Summary

### 1. Q&A

* **Q: What are the missing libraries that need to be installed?**
    * **A:** `streamlit` and `youtube_transcript_api` are identified as missing libraries during the data exploration phase.
* **Q: What is the default model used if a specific model is not specified?**
    * **A:**  `sshleifer/distilbart-cnn-12-6` is used as the default model for NLP tasks in the code.
* **Q: Why was the code execution marked as a failure?**
    * **A:** The code execution was marked as a failure because it did not generate any output. This lack of output suggests an unexpected behavior or a potential issue within the code.


### 2. Data Analysis Key Findings

* **Missing Libraries:** `streamlit` and `youtube_transcript_api` libraries were identified as missing during the code analysis.
* **Default Hugging Face Model:** The code utilizes `sshleifer/distilbart-cnn-12-6` as a default model when a specific model is not specified.
* **No Transcript Found:** During code evaluation, it was found that the code execution did not produce any output, possibly due to the inability to find a YouTube transcript.
* **Streamlit Warnings:** The code generated warnings during execution because it was not run using the `streamlit run` command. This is expected as Streamlit needs a specific environment for proper display.


### 3. Insights or Next Steps

* **Debug Code for Output:** The primary next step is to debug the code to understand why it's not producing any output. This could involve adding print statements, inspecting the logic related to YouTube transcript retrieval, and reviewing the code for potential errors.
* **Run with Streamlit:** To fully visualize and interact with the Streamlit application, it should be executed using the `streamlit run` command in a suitable environment.

"""

# prompt: input as url of youtube video and give sumarize

# Install necessary libraries if not already installed
!pip install streamlit youtube_transcript_api transformers nltk

import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi
from transformers import pipeline
import nltk

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# Initialize the summarization model
summarizer = pipeline("summarization")

# Function to extract video ID from URL
def extract_video_id(url):
    if "youtube.com/watch?v=" in url:
        return url.split("youtube.com/watch?v=")[1].split("&")[0]
    elif "youtu.be/" in url:
        return url.split("youtu.be/")[1].split("&")[0]
    return url  # Return as is if already an ID

# Function to fetch and summarize YouTube video transcript
def summarize_youtube_video(video_id, max_word_count=10000):
    try:
        transcript = YouTubeTranscriptApi.get_transcript(video_id)
        text = " ".join([entry['text'] for entry in transcript])

        # Split text into smaller chunks (model limitation ~1024 tokens per request)
        chunk_size = 1000  # Adjust as needed
        text_chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]

        summaries = []
        for chunk in text_chunks:
            summary = summarizer(chunk, max_length=500, min_length=100, do_sample=False)[0]['summary_text']
            summaries.append(summary)

        # Combine all summaries into a single text
        final_summary = " ".join(summaries)

        # Trim to max_word_count if needed
        final_summary_words = final_summary.split()
        if len(final_summary_words) > max_word_count:
            final_summary = " ".join(final_summary_words[:max_word_count])

        return final_summary
    except Exception as e:
        return f"Error fetching transcript: {e}"


# Streamlit GUI
st.title("YouTube Video Summarizer")
st.write("Enter a YouTube video URL or ID to generate a summary.")

video_url = st.text_input("Enter YouTube Video URL or ID:")

if st.button("Summarize Video") and video_url:
    video_id = extract_video_id(video_url)
    with st.spinner("Fetching and summarizing transcript..."):
        summary = summarize_youtube_video(video_id)
        st.subheader("Summary:")
        st.write(summary)